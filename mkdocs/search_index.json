{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to MkDocs\n\n\nFor full documentation visit \nmkdocs.org\n.\n\n\nCommands\n\n\n\n\nmkdocs new [dir-name]\n - Create a new project.\n\n\nmkdocs serve\n - Start the live-reloading docs server.\n\n\nmkdocs build\n - Build the documentation site.\n\n\nmkdocs help\n - Print this help message.\n\n\n\n\nProject layout\n\n\nmkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.", 
            "title": "一. 介绍"
        }, 
        {
            "location": "/#welcome-to-mkdocs", 
            "text": "For full documentation visit  mkdocs.org .", 
            "title": "Welcome to MkDocs"
        }, 
        {
            "location": "/#commands", 
            "text": "mkdocs new [dir-name]  - Create a new project.  mkdocs serve  - Start the live-reloading docs server.  mkdocs build  - Build the documentation site.  mkdocs help  - Print this help message.", 
            "title": "Commands"
        }, 
        {
            "location": "/#project-layout", 
            "text": "mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.", 
            "title": "Project layout"
        }, 
        {
            "location": "/install/", 
            "text": "", 
            "title": "二. 安装"
        }, 
        {
            "location": "/ovs/", 
            "text": "同宿主，同子网的2台VM互通\n\n\n\n\n# 建立桥接\novs-vsctl add-br br-int\n\n# 用veth模拟vm，将veth在宿主上的一端加入桥接\novs-vsctl add-port br-int poi-vm1\novs-vsctl add-port br-int poi-vm2\n\n\n\n\n同宿主，不同子网之间隔离（分别桥接）\n\n\n\n\n# 建立桥接，biv-100是子网1，biv-200是子网2\novs-vsctl add-br biv-100\novs-vsctl add-br biv-200\n\n# 用veth模拟vm，2个vm在宿主上的一端分别加入2个桥接\novs-vsctl add-port biv-100 poi-vm1\novs-vsctl add-port biv-200 poi-vm2\n\n\n\n\n同宿主，不同子网之间隔离（打tag）\n\n\n\n\n# 建立桥接\novs-vsctl add-br br-int\n\n# 用veth模拟vm，2个vm在宿主上的一端加入桥接，同时打tag\novs-vsctl add-port br-int poi-vm1 -- set port poi-vm1 tag=100\novs-vsctl add-port br-int poi-vm2 -- set port poi-vm2 tag=200\n\n\n\n\n同宿主，不同桥接之间二层互通\n\n\n\n\n# 建立桥接\novs-vsctl add-br biv-100\novs-vsctl add-br biv-200\n\n# 创建patch port，2端分别桥接到biv-100和biv-200\novs-vsctl add-port biv-100 patch-to-200 -- set interface patch-to-200 type=patch -- set interface patch-to-200 options:peer=patch-to-100\novs-vsctl add-port biv-200 patch-to-100 -- set interface patch-to-100 type=patch -- set interface patch-to-100 options:peer=patch-to-200\n\n# 用veth模拟vm，vm在宿主的一端加入桥接\novs-vsctl add-port biv-100 poi-vm1\novs-vsctl add-port biv-200 poi-vm2\n\n\n\n\n不同宿主，同子网互通这么做会环路\n\n\n\n\n\n\n这样看上去好像没啥问题，但是这个图可以画成这样：\n\n\n\n\n这样就形成了一个环路，如果宿主机就2台还不会环路，只要达到3台就会开始环路\n\n\n注意：我们当前用linux bridge没有环路是因为无论是多播vtep还是单播vtep，一个桥接网卡都只桥接一个vtep，而广播包（或者叫泛洪）的特性是数据包从非入口的所有端口泛洪出去，即如果一个linux bridge桥接2个vtep，也是会造成环路的\n\n\n其实openstack的网络架构图画出来看也是有环路的：\n\n\n\n\n那么为什么没有环路呢，是因为如果br-tun只是个简单的switch/hub功能，那么是会环路的，vtep收到数据包后会从br-tun的另一个vtep泛洪出去。但br-tun是openflow控制的，其中2条规则起了关键作用：\n\n\n\n\n\n\nbr-tun从vtep收到数据包后，将vni去掉，加上vlan头，这还不是关键，关键是第2点\n\n\n\n\n\n\n然后将数据包从patch-int端口发出，即这个数据包只发到br-int而不会交到另一个vtep上，因此不会产生环路\n\n\n\n\n\n\niptables/ebtables对ovs port不起作用\n\n\n\n\n经测试，使用iptables和ebtables对ovs端口不起任何作用，只对linux bridge的端口起作用", 
            "title": "三. ovs"
        }, 
        {
            "location": "/ovs/#2vm", 
            "text": "# 建立桥接\novs-vsctl add-br br-int\n\n# 用veth模拟vm，将veth在宿主上的一端加入桥接\novs-vsctl add-port br-int poi-vm1\novs-vsctl add-port br-int poi-vm2", 
            "title": "同宿主，同子网的2台VM互通"
        }, 
        {
            "location": "/ovs/#_1", 
            "text": "# 建立桥接，biv-100是子网1，biv-200是子网2\novs-vsctl add-br biv-100\novs-vsctl add-br biv-200\n\n# 用veth模拟vm，2个vm在宿主上的一端分别加入2个桥接\novs-vsctl add-port biv-100 poi-vm1\novs-vsctl add-port biv-200 poi-vm2", 
            "title": "同宿主，不同子网之间隔离（分别桥接）"
        }, 
        {
            "location": "/ovs/#tag", 
            "text": "# 建立桥接\novs-vsctl add-br br-int\n\n# 用veth模拟vm，2个vm在宿主上的一端加入桥接，同时打tag\novs-vsctl add-port br-int poi-vm1 -- set port poi-vm1 tag=100\novs-vsctl add-port br-int poi-vm2 -- set port poi-vm2 tag=200", 
            "title": "同宿主，不同子网之间隔离（打tag）"
        }, 
        {
            "location": "/ovs/#_2", 
            "text": "# 建立桥接\novs-vsctl add-br biv-100\novs-vsctl add-br biv-200\n\n# 创建patch port，2端分别桥接到biv-100和biv-200\novs-vsctl add-port biv-100 patch-to-200 -- set interface patch-to-200 type=patch -- set interface patch-to-200 options:peer=patch-to-100\novs-vsctl add-port biv-200 patch-to-100 -- set interface patch-to-100 type=patch -- set interface patch-to-100 options:peer=patch-to-200\n\n# 用veth模拟vm，vm在宿主的一端加入桥接\novs-vsctl add-port biv-100 poi-vm1\novs-vsctl add-port biv-200 poi-vm2", 
            "title": "同宿主，不同桥接之间二层互通"
        }, 
        {
            "location": "/ovs/#_3", 
            "text": "这样看上去好像没啥问题，但是这个图可以画成这样：   这样就形成了一个环路，如果宿主机就2台还不会环路，只要达到3台就会开始环路  注意：我们当前用linux bridge没有环路是因为无论是多播vtep还是单播vtep，一个桥接网卡都只桥接一个vtep，而广播包（或者叫泛洪）的特性是数据包从非入口的所有端口泛洪出去，即如果一个linux bridge桥接2个vtep，也是会造成环路的  其实openstack的网络架构图画出来看也是有环路的：   那么为什么没有环路呢，是因为如果br-tun只是个简单的switch/hub功能，那么是会环路的，vtep收到数据包后会从br-tun的另一个vtep泛洪出去。但br-tun是openflow控制的，其中2条规则起了关键作用：    br-tun从vtep收到数据包后，将vni去掉，加上vlan头，这还不是关键，关键是第2点    然后将数据包从patch-int端口发出，即这个数据包只发到br-int而不会交到另一个vtep上，因此不会产生环路", 
            "title": "不同宿主，同子网互通这么做会环路"
        }, 
        {
            "location": "/ovs/#iptablesebtablesovs-port", 
            "text": "经测试，使用iptables和ebtables对ovs端口不起任何作用，只对linux bridge的端口起作用", 
            "title": "iptables/ebtables对ovs port不起作用"
        }, 
        {
            "location": "/openflow/", 
            "text": "查看\n\n\n\n\n# 查看openflow端口信息\novs-ofctl show ovs-switch\n\n# 查看openflow端口编号\novs-vsctl get interface p0 ofport\n\n# 查看datapath\novs-dpctl show\n\n# 查看流表\novs-ofctl dump-flows ovs-switch\n\n\n\n\n流表操作\n\n\n\n\n默认规则\n\n\n每个交换机创建之后默认都有一条流表规则，用于允许所有流量通过\n\n\nNXST_FLOW reply (xid=0x4):\n\n cookie=0x0, duration=1588.919s, table=0, n_packets=50, n_bytes=3260, idle_age=0, priority=0 actions=NORMAL\n\n\n\n\n加亮这条就是默认的流表，如果这条删掉，那么当其他条目都没匹配到的时候，数据包就会被丢弃\n\n\n添加规则\n\n\n# 屏蔽所有进入 OVS 的以太网广播数据包\novs-ofctl add-flow ovs-switch \ntable=0, dl_src=01:00:00:00:00:00/01:00:00:00:00:00, actions=drop\n\n\n\n\n\n流表参数详解\n\n\novs-ofctl dump-flows ovs-switch\n\n\n\n\n输出\n\n\nNXST_FLOW reply (xid=0x4):\ncookie=0x0, duration=7.672s, table=0, n_packets=0, n_bytes=0, idle_age=7, priority=0 actions=NORMAL\n\n\n\n\n\n\n\n\ncookie: 不了解，官方manpage解释如下\n\n\nmanpage\nAn opaque identifier called a cookie can be used as a handle to identify a set of flows:\n\ncookie=value\n    A cookie can be associated with a flow using the add-flow, add-flows, and mod-flows commands.  value can be any 64-bit number and need not be unique among flows. If this field is omitted, a default cookie value of 0 is used.\n\ncookie=value/mask\n    When using NXM, the cookie can be used as a handle for querying, modifying, and deleting flows. value and mask may be supplied for the del-flows, mod-flows, dump-flows, and dump-aggregate commands to limit matching cookies. A 1-bit in mask indicates that the corresponding bit in cookie must match exactly, and a 0-bit wildcards that bit. A mask of -1 may be used to exactly match a cookie.\n\n    The  mod-flows  command can update the cookies of flows that match a cookie by specifying the cookie field twice (once with a mask for matching and once without to indicate the new value):\n\n    ovs-ofctl mod-flows br0 cookie=1,actions=normal\n        Change all flows\n cookies to 1 and change their actions to normal.\n\n    ovs-ofctl mod-flows br0 cookie=1/-1,cookie=2,actions=normal\n        Update cookies with a value of 1 to 2 and change their actions to normal.\n\n    The ability to match on cookies was added in Open vSwitch 1.5.0.\n\n\n\n\n\n\n\nduration: 该条目创建多久了\n\n\n\n\n\n\ntable: 该条目所属table\n\n\n\n\n\n\nn_packets: 匹配了多少个包，注意是匹配，即如果该条目有被查询过，但是没匹配上，那么数值是不会增加的\n\n\n\n\n\n\nn_bytes: 匹配的所有包的大小总和，注意是匹配，即如果该条目有被查询过，但是没匹配上，那么数值是不会增加的\n\n\n\n\n\n\nidle_age: 该条目多久没被匹配了，注意是匹配，即如果该条目有被查询过，但是没匹配上，那么数值是不会增加的\n\n\n\n\n\n\npriority: 表内条目优先级，0-65535，数字越过越优先，不指定优先级则为32768，相同优先级的话，先插入的优先（dump-flows结果中靠上的优先）\n\n\n\n\n\n\nactions: 匹配之后的操作\n\n\n\n\n\n\n实验\n\n\n\n\n使用openflow转发包到多个端口\n\n\n转到任何端口的方法都是一样的，包括veth和vtep。效果等同于用linux bridge时候的bridge fdb append\n\n\n# 先清空默认条目，以免导致环路，也是为了更了解数据包\novs-ofctl del-flows br-tun\n\n# \b转到openflow端口1、2、3、4\novs-ofctl add-flow br-tun \ntable=0, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00, actions=output:1,2,3,4\n\n\n\n\n\n上面的\n\n\nactions=output:1,2,3,4\n\n\n\n\n等同于(ovs-ofctl就可以看到自动翻译成如下)\n\n\nactions=output:1,output:2,output:3,output:4\n\n\n\n\n流表匹配顺序\n\n\n\n\ntable -\n flow priority\n\n\n即先从table开始，从0到254，在table里有多个openflow条目，根据优先级priority最高的优先匹配", 
            "title": "四. openflow"
        }, 
        {
            "location": "/openflow/#_1", 
            "text": "# 查看openflow端口信息\novs-ofctl show ovs-switch\n\n# 查看openflow端口编号\novs-vsctl get interface p0 ofport\n\n# 查看datapath\novs-dpctl show\n\n# 查看流表\novs-ofctl dump-flows ovs-switch", 
            "title": "查看"
        }, 
        {
            "location": "/openflow/#_2", 
            "text": "", 
            "title": "流表操作"
        }, 
        {
            "location": "/openflow/#_3", 
            "text": "每个交换机创建之后默认都有一条流表规则，用于允许所有流量通过  NXST_FLOW reply (xid=0x4):  cookie=0x0, duration=1588.919s, table=0, n_packets=50, n_bytes=3260, idle_age=0, priority=0 actions=NORMAL  加亮这条就是默认的流表，如果这条删掉，那么当其他条目都没匹配到的时候，数据包就会被丢弃", 
            "title": "默认规则"
        }, 
        {
            "location": "/openflow/#_4", 
            "text": "# 屏蔽所有进入 OVS 的以太网广播数据包\novs-ofctl add-flow ovs-switch  table=0, dl_src=01:00:00:00:00:00/01:00:00:00:00:00, actions=drop", 
            "title": "添加规则"
        }, 
        {
            "location": "/openflow/#_5", 
            "text": "ovs-ofctl dump-flows ovs-switch  输出  NXST_FLOW reply (xid=0x4):\ncookie=0x0, duration=7.672s, table=0, n_packets=0, n_bytes=0, idle_age=7, priority=0 actions=NORMAL    cookie: 不了解，官方manpage解释如下  manpage An opaque identifier called a cookie can be used as a handle to identify a set of flows:\n\ncookie=value\n    A cookie can be associated with a flow using the add-flow, add-flows, and mod-flows commands.  value can be any 64-bit number and need not be unique among flows. If this field is omitted, a default cookie value of 0 is used.\n\ncookie=value/mask\n    When using NXM, the cookie can be used as a handle for querying, modifying, and deleting flows. value and mask may be supplied for the del-flows, mod-flows, dump-flows, and dump-aggregate commands to limit matching cookies. A 1-bit in mask indicates that the corresponding bit in cookie must match exactly, and a 0-bit wildcards that bit. A mask of -1 may be used to exactly match a cookie.\n\n    The  mod-flows  command can update the cookies of flows that match a cookie by specifying the cookie field twice (once with a mask for matching and once without to indicate the new value):\n\n    ovs-ofctl mod-flows br0 cookie=1,actions=normal\n        Change all flows  cookies to 1 and change their actions to normal.\n\n    ovs-ofctl mod-flows br0 cookie=1/-1,cookie=2,actions=normal\n        Update cookies with a value of 1 to 2 and change their actions to normal.\n\n    The ability to match on cookies was added in Open vSwitch 1.5.0.    duration: 该条目创建多久了    table: 该条目所属table    n_packets: 匹配了多少个包，注意是匹配，即如果该条目有被查询过，但是没匹配上，那么数值是不会增加的    n_bytes: 匹配的所有包的大小总和，注意是匹配，即如果该条目有被查询过，但是没匹配上，那么数值是不会增加的    idle_age: 该条目多久没被匹配了，注意是匹配，即如果该条目有被查询过，但是没匹配上，那么数值是不会增加的    priority: 表内条目优先级，0-65535，数字越过越优先，不指定优先级则为32768，相同优先级的话，先插入的优先（dump-flows结果中靠上的优先）    actions: 匹配之后的操作", 
            "title": "流表参数详解"
        }, 
        {
            "location": "/openflow/#_6", 
            "text": "", 
            "title": "实验"
        }, 
        {
            "location": "/openflow/#openflow", 
            "text": "转到任何端口的方法都是一样的，包括veth和vtep。效果等同于用linux bridge时候的bridge fdb append  # 先清空默认条目，以免导致环路，也是为了更了解数据包\novs-ofctl del-flows br-tun\n\n# \b转到openflow端口1、2、3、4\novs-ofctl add-flow br-tun  table=0, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00, actions=output:1,2,3,4   上面的  actions=output:1,2,3,4  等同于(ovs-ofctl就可以看到自动翻译成如下)  actions=output:1,output:2,output:3,output:4", 
            "title": "使用openflow转发包到多个端口"
        }, 
        {
            "location": "/openflow/#_7", 
            "text": "table -  flow priority  即先从table开始，从0到254，在table里有多个openflow条目，根据优先级priority最高的优先匹配", 
            "title": "流表匹配顺序"
        }, 
        {
            "location": "/test/test1/", 
            "text": "架构图\n\n\n\n\n物理图\n\n\n\n\n逻辑图\n\n\n\n\n流表图\n\n\n\n\nNode 1\n\n\n\n\n\n\n\n\novs.sh\n\n\n点击打开\n# 删除ovs桥接\n\novs-vsctl del-br br-int\n\n\n# 创建ovs桥接\n\novs-vsctl add-br br-int\n\n\n# 清空流表\n\novs-ofctl del-flows br-int\n\n\n# 创建vtep\n\novs-vsctl add-port br-int vtep137 -- \nset\n interface vtep137 \ntype\n=\nvxlan options:remote_ip\n=\n172\n.16.1.137 options:ttl\n=\n64\n options:in_key\n=\nflow options:out_key\n=\nflow\novs-vsctl add-port br-int vtep138 -- \nset\n interface vtep138 \ntype\n=\nvxlan options:remote_ip\n=\n172\n.16.1.138 options:ttl\n=\n64\n options:in_key\n=\nflow options:out_key\n=\nflow\n\n\n\n\n\n\n\nbridge.sh\n\n\n点击打开\nbrctl delbr biv-1001100\nbrctl delbr biv-1234567\n\nbrctl addbr biv-1001100\nip link \nset\n biv-1001100 up\n\nbrctl addbr biv-1234567\nip link \nset\n biv-1234567 up\n\n\n\n\n\n\n\nbr-to-ovs.sh\n\n\n点击打开\nip link delete vib-1001100\nip link delete vib-1234567\n\nip link add vib-1001100 \ntype\n veth peer name vio-1001100\nbrctl addif biv-1001100 vib-1001100\nip link \nset\n vib-1001100 up\nip link \nset\n vio-1001100 up\novs-vsctl add-port br-int vio-1001100\n\nip link add vib-1234567 \ntype\n veth peer name vio-1234567\nbrctl addif biv-1234567 vib-1234567\nip link \nset\n vib-1234567 up\nip link \nset\n vio-1234567 up\novs-vsctl add-port br-int vio-1234567\n\n\n\n\n\n\n\nopenflow.sh\n\n\n点击打开\n# 写openflow规则顺序：\n\n\n# 1. 从表0开始\n\n\n# 2. 为每个表之间留一些表，用于今后扩展\n\n\n# 3. 跳表时候只往高了跳，不往低了跳\n\n\n# 4. priority=1的写规则，可存在多条；priotity=0的只能有一条，用于其余数据包处理\n\n\n\n# 获得openflow端口\n\n\nvio1001100_ofport\n=\n`\novs-vsctl get interface vio-1001100 ofport\n`\n\n\nvio1234567_ofport\n=\n`\novs-vsctl get interface vio-1234567 ofport\n`\n\n\nvtep137_ofport\n=\n`\novs-vsctl get interface vtep137 ofport\n`\n\n\nvtep138_ofport\n=\n`\novs-vsctl get interface vtep138 ofport\n`\n\n\n\n\n# table 0\n\n\n## 从linux-bridge过来的数据包，扔给table 2处理\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvio1001100_ofport\n}\n, actions=goto_table:2\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvio1234567_ofport\n}\n, actions=goto_table:2\n\n\n\n## 从vtep过来的数据包，扔给table 10处理\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvtep137_ofport\n}\n actions=goto_table:10\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvtep138_ofport\n}\n actions=goto_table:10\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=0, priority=0, actions=drop\n\n\n\n\n# table 2\n\n\n## 单播包，扔给table 20处理\n\novs-ofctl add-flow br-int \ntable=2, priority=1, dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:20\n\n\n\n## 多播和广播包，扔给table 22处理\n\novs-ofctl add-flow br-int \ntable=2, priority=1, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:22\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=2, priority=0, actions=drop\n\n\n\n\n# table 10\n\n\n## 学习从vtep过来的数据包，往table 20中添加返程规则，然后输出到linux-bridge端口\n\n\n## 具体学习内容:\n\n\n##   1. 包的目的mac跟当前的源mac匹配\n\n\n##   2. 将tunnel号修改为当前的tunnel号\n\n\n##   3. 从当前入口发出\n\novs-ofctl add-flow br-int \ntable=10, priority=1, tun_id=1001100, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]-\nNXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:\n${\nvio1001100_ofport\n}\n\novs-ofctl add-flow br-int \ntable=10, priority=1, tun_id=1234567, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]-\nNXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:\n${\nvio1234567_ofport\n}\n\n\n\n## 其余DROP（可选）\n\novs-ofctl add-flow br-int \ntable=10, priority=0, actions=drop\n\n\n\n\n# table 20\n\n\n## 有学习到规则的数据包，根据规则打上tunnel号并从对应的vtep port发出（动态，不用写规则）\n\n\n\n## 其余扔给table 22处理\n\novs-ofctl add-flow br-int \ntable=20, priority=0, actions=goto_table:22\n\n\n\n\n# table 22\n\n\n## 匹配in_port后打上tunnel号，并从对应的vtep port发出（多条）\n\novs-ofctl add-flow br-int \ntable=22, priority=1, in_port=\n${\nvio1001100_ofport\n}\n, actions=set_tunnel:1001100,output:\n${\nvtep137_ofport\n}\n,\n${\nvtep138_ofport\n}\n\novs-ofctl add-flow br-int \ntable=22, priority=1, in_port=\n${\nvio1234567_ofport\n}\n, actions=set_tunnel:1234567,output:\n${\nvtep137_ofport\n}\n,\n${\nvtep138_ofport\n}\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=22, priority=0, actions=drop\n\n\n\n\n\n\n\n\nvm.sh\n\n\n点击打开\nip netns del s1-vm1\nip netns del s1-vm2\nip netns del s2-vm1\nip netns del s2-vm2\n\nip netns add s1-vm1\nip link add poi-s1-vm1 \ntype\n veth peer name pii-s1-vm1\nip link \nset\n pii-s1-vm1 netns s1-vm1\nip netns \nexec\n s1-vm1 ip link \nset\n lo up\nip netns \nexec\n s1-vm1 ip addr add \n192\n.168.1.1/24 dev pii-s1-vm1\nip netns \nexec\n s1-vm1 ip link \nset\n pii-s1-vm1 up\nip netns \nexec\n s1-vm1 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s1-vm1 up\nbrctl addif biv-1001100 poi-s1-vm1\n\nip netns add s1-vm2\nip link add poi-s1-vm2 \ntype\n veth peer name pii-s1-vm2\nip link \nset\n pii-s1-vm2 netns s1-vm2\nip netns \nexec\n s1-vm2 ip link \nset\n lo up\nip netns \nexec\n s1-vm2 ip addr add \n192\n.168.1.2/24 dev pii-s1-vm2\nip netns \nexec\n s1-vm2 ip link \nset\n pii-s1-vm2 up\nip netns \nexec\n s1-vm2 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s1-vm2 up\nbrctl addif biv-1001100 poi-s1-vm2\n\nip netns add s2-vm1\nip link add poi-s2-vm1 \ntype\n veth peer name pii-s2-vm1\nip link \nset\n pii-s2-vm1 netns s2-vm1\nip netns \nexec\n s2-vm1 ip link \nset\n lo up\nip netns \nexec\n s2-vm1 ip addr add \n192\n.168.2.1/24 dev pii-s2-vm1\nip netns \nexec\n s2-vm1 ip link \nset\n pii-s2-vm1 up\nip netns \nexec\n s2-vm1 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s2-vm1 up\nbrctl addif biv-1234567 poi-s2-vm1\n\nip netns add s2-vm2\nip link add poi-s2-vm2 \ntype\n veth peer name pii-s2-vm2\nip link \nset\n pii-s2-vm2 netns s2-vm2\nip netns \nexec\n s2-vm2 ip link \nset\n lo up\nip netns \nexec\n s2-vm2 ip addr add \n192\n.168.2.2/24 dev pii-s2-vm2\nip netns \nexec\n s2-vm2 ip link \nset\n pii-s2-vm2 up\nip netns \nexec\n s2-vm2 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s2-vm2 up\nbrctl addif biv-1234567 poi-s2-vm2\n\n\n\n\n\n\n\nNode 2\n\n\n\n\n\n\n\n\novs.sh\n\n\n点击打开\n# 删除ovs桥接\n\novs-vsctl del-br br-int\n\n\n# 创建ovs桥接\n\novs-vsctl add-br br-int\n\n\n# 清空流表\n\novs-ofctl del-flows br-int\n\n\n# 创建vtep\n\novs-vsctl add-port br-int vtep136 -- \nset\n interface vtep136 \ntype\n=\nvxlan options:remote_ip\n=\n172\n.16.1.136 options:ttl\n=\n64\n options:in_key\n=\nflow options:out_key\n=\nflow\novs-vsctl add-port br-int vtep138 -- \nset\n interface vtep138 \ntype\n=\nvxlan options:remote_ip\n=\n172\n.16.1.138 options:ttl\n=\n64\n options:in_key\n=\nflow options:out_key\n=\nflow\n\n\n\n\n\n\n\nbridge.sh\n\n\n点击打开\nbrctl delbr biv-1001100\nbrctl delbr biv-1234567\n\nbrctl addbr biv-1001100\nip link \nset\n biv-1001100 up\n\nbrctl addbr biv-1234567\nip link \nset\n biv-1234567 up\n\n\n\n\n\n\n\nbr-to-ovs.sh\n\n\n点击打开\nip link delete vib-1001100\nip link delete vib-1234567\n\nip link add vib-1001100 \ntype\n veth peer name vio-1001100\nbrctl addif biv-1001100 vib-1001100\nip link \nset\n vib-1001100 up\nip link \nset\n vio-1001100 up\novs-vsctl add-port br-int vio-1001100\n\nip link add vib-1234567 \ntype\n veth peer name vio-1234567\nbrctl addif biv-1234567 vib-1234567\nip link \nset\n vib-1234567 up\nip link \nset\n vio-1234567 up\novs-vsctl add-port br-int vio-1234567\n\n\n\n\n\n\n\nopenflow.sh\n\n\n点击打开\n# 写openflow规则顺序：\n\n\n# 1. 从表0开始\n\n\n# 2. 为每个表之间留一些表，用于今后扩展\n\n\n# 3. 跳表时候只往高了跳，不往低了跳\n\n\n# 4. priority=1的写规则，可存在多条；priotity=0的只能有一条，用于其余数据包处理\n\n\n\n# 获得openflow端口\n\n\nvio1001100_ofport\n=\n`\novs-vsctl get interface vio-1001100 ofport\n`\n\n\nvio1234567_ofport\n=\n`\novs-vsctl get interface vio-1234567 ofport\n`\n\n\nvtep136_ofport\n=\n`\novs-vsctl get interface vtep136 ofport\n`\n\n\nvtep138_ofport\n=\n`\novs-vsctl get interface vtep138 ofport\n`\n\n\n\n\n# table 0\n\n\n## 从linux-bridge过来的数据包，扔给table 2处理\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvio1001100_ofport\n}\n, actions=goto_table:2\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvio1234567_ofport\n}\n, actions=goto_table:2\n\n\n\n## 从vtep过来的数据包，扔给table 10处理\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvtep136_ofport\n}\n actions=goto_table:10\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvtep138_ofport\n}\n actions=goto_table:10\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=0, priority=0, actions=drop\n\n\n\n\n# table 2\n\n\n## 单播包，扔给table 20处理\n\novs-ofctl add-flow br-int \ntable=2, priority=1, dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:20\n\n\n\n## 多播和广播包，扔给table 22处理\n\novs-ofctl add-flow br-int \ntable=2, priority=1, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:22\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=2, priority=0, actions=drop\n\n\n\n\n# table 10\n\n\n## 学习从vtep过来的数据包，往table 20中添加返程规则，然后输出到linux-bridge端口\n\n\n## 具体学习内容:\n\n\n##   1. 包的目的mac跟当前的源mac匹配\n\n\n##   2. 将tunnel号修改为当前的tunnel号\n\n\n##   3. 从当前入口发出\n\novs-ofctl add-flow br-int \ntable=10, priority=1, tun_id=1001100, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]-\nNXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:\n${\nvio1001100_ofport\n}\n\novs-ofctl add-flow br-int \ntable=10, priority=1, tun_id=1234567, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]-\nNXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:\n${\nvio1234567_ofport\n}\n\n\n\n## 其余DROP（可选）\n\novs-ofctl add-flow br-int \ntable=10, priority=0, actions=drop\n\n\n\n\n# table 20\n\n\n## 有学习到规则的数据包，根据规则打上tunnel号并从对应的vtep port发出（动态，不用写规则）\n\n\n\n## 其余扔给table 22处理\n\novs-ofctl add-flow br-int \ntable=20, priority=0, actions=goto_table:22\n\n\n\n\n# table 22\n\n\n## 匹配in_port后打上tunnel号，并从对应的vtep port发出（多条）\n\novs-ofctl add-flow br-int \ntable=22, priority=1, in_port=\n${\nvio1001100_ofport\n}\n, actions=set_tunnel:1001100,output:\n${\nvtep136_ofport\n}\n,\n${\nvtep138_ofport\n}\n\novs-ofctl add-flow br-int \ntable=22, priority=1, in_port=\n${\nvio1234567_ofport\n}\n, actions=set_tunnel:1234567,output:\n${\nvtep136_ofport\n}\n,\n${\nvtep138_ofport\n}\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=22, priority=0, actions=drop\n\n\n\n\n\n\n\n\nvm.sh\n\n\n点击打开\nip netns del s1-vm3\nip netns del s1-vm4\nip netns del s2-vm3\nip netns del s2-vm4\n\nip netns add s1-vm3\nip link add poi-s1-vm3 \ntype\n veth peer name pii-s1-vm3\nip link \nset\n pii-s1-vm3 netns s1-vm3\nip netns \nexec\n s1-vm3 ip link \nset\n lo up\nip netns \nexec\n s1-vm3 ip addr add \n192\n.168.1.3/24 dev pii-s1-vm3\nip netns \nexec\n s1-vm3 ip link \nset\n pii-s1-vm3 up\nip netns \nexec\n s1-vm3 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s1-vm3 up\nbrctl addif biv-1001100 poi-s1-vm3\n\nip netns add s1-vm4\nip link add poi-s1-vm4 \ntype\n veth peer name pii-s1-vm4\nip link \nset\n pii-s1-vm4 netns s1-vm4\nip netns \nexec\n s1-vm4 ip link \nset\n lo up\nip netns \nexec\n s1-vm4 ip addr add \n192\n.168.1.4/24 dev pii-s1-vm4\nip netns \nexec\n s1-vm4 ip link \nset\n pii-s1-vm4 up\nip netns \nexec\n s1-vm4 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s1-vm4 up\nbrctl addif biv-1001100 poi-s1-vm4\n\nip netns add s2-vm3\nip link add poi-s2-vm3 \ntype\n veth peer name pii-s2-vm3\nip link \nset\n pii-s2-vm3 netns s2-vm3\nip netns \nexec\n s2-vm3 ip link \nset\n lo up\nip netns \nexec\n s2-vm3 ip addr add \n192\n.168.2.3/24 dev pii-s2-vm3\nip netns \nexec\n s2-vm3 ip link \nset\n pii-s2-vm3 up\nip netns \nexec\n s2-vm3 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s2-vm3 up\nbrctl addif biv-1234567 poi-s2-vm3\n\nip netns add s2-vm4\nip link add poi-s2-vm4 \ntype\n veth peer name pii-s2-vm4\nip link \nset\n pii-s2-vm4 netns s2-vm4\nip netns \nexec\n s2-vm4 ip link \nset\n lo up\nip netns \nexec\n s2-vm4 ip addr add \n192\n.168.2.4/24 dev pii-s2-vm4\nip netns \nexec\n s2-vm4 ip link \nset\n pii-s2-vm4 up\nip netns \nexec\n s2-vm4 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s2-vm4 up\nbrctl addif biv-1234567 poi-s2-vm4\n\n\n\n\n\n\n\nNode 3\n\n\n\n\n\n\n\n\novs.sh\n\n\n点击打开\n# 删除ovs桥接\n\novs-vsctl del-br br-int\n\n\n# 创建ovs桥接\n\novs-vsctl add-br br-int\n\n\n# 清空流表\n\novs-ofctl del-flows br-int\n\n\n# 创建vtep\n\novs-vsctl add-port br-int vtep137 -- \nset\n interface vtep137 \ntype\n=\nvxlan options:remote_ip\n=\n172\n.16.1.137 options:ttl\n=\n64\n options:in_key\n=\nflow options:out_key\n=\nflow\novs-vsctl add-port br-int vtep136 -- \nset\n interface vtep136 \ntype\n=\nvxlan options:remote_ip\n=\n172\n.16.1.136 options:ttl\n=\n64\n options:in_key\n=\nflow options:out_key\n=\nflow\n\n\n\n\n\n\n\nbridge.sh\n\n\n点击打开\nbrctl delbr biv-1001100\nbrctl delbr biv-1234567\n\nbrctl addbr biv-1001100\nip link \nset\n biv-1001100 up\n\nbrctl addbr biv-1234567\nip link \nset\n biv-1234567 up\n\n\n\n\n\n\n\nbr-to-ovs.sh\n\n\n点击打开\nip link delete vib-1001100\nip link delete vib-1234567\n\nip link add vib-1001100 \ntype\n veth peer name vio-1001100\nbrctl addif biv-1001100 vib-1001100\nip link \nset\n vib-1001100 up\nip link \nset\n vio-1001100 up\novs-vsctl add-port br-int vio-1001100\n\nip link add vib-1234567 \ntype\n veth peer name vio-1234567\nbrctl addif biv-1234567 vib-1234567\nip link \nset\n vib-1234567 up\nip link \nset\n vio-1234567 up\novs-vsctl add-port br-int vio-1234567\n\n\n\n\n\n\n\nopenflow.sh\n\n\n点击打开\n# 写openflow规则顺序：\n\n\n# 1. 从表0开始\n\n\n# 2. 为每个表之间留一些表，用于今后扩展\n\n\n# 3. 跳表时候只往高了跳，不往低了跳\n\n\n# 4. priority=1的写规则，可存在多条；priotity=0的只能有一条，用于其余数据包处理\n\n\n\n# 获得openflow端口\n\n\nvio1001100_ofport\n=\n`\novs-vsctl get interface vio-1001100 ofport\n`\n\n\nvio1234567_ofport\n=\n`\novs-vsctl get interface vio-1234567 ofport\n`\n\n\nvtep137_ofport\n=\n`\novs-vsctl get interface vtep137 ofport\n`\n\n\nvtep136_ofport\n=\n`\novs-vsctl get interface vtep136 ofport\n`\n\n\n\n\n# table 0\n\n\n## 从linux-bridge过来的数据包，扔给table 2处理\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvio1001100_ofport\n}\n, actions=goto_table:2\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvio1234567_ofport\n}\n, actions=goto_table:2\n\n\n\n## 从vtep过来的数据包，扔给table 10处理\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvtep137_ofport\n}\n actions=goto_table:10\n\novs-ofctl add-flow br-int \ntable=0, priority=1, in_port=\n${\nvtep136_ofport\n}\n actions=goto_table:10\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=0, priority=0, actions=drop\n\n\n\n\n# table 2\n\n\n## 单播包，扔给table 20处理\n\novs-ofctl add-flow br-int \ntable=2, priority=1, dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:20\n\n\n\n## 多播和广播包，扔给table 22处理\n\novs-ofctl add-flow br-int \ntable=2, priority=1, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:22\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=2, priority=0, actions=drop\n\n\n\n\n# table 10\n\n\n## 学习从vtep过来的数据包，往table 20中添加返程规则，然后输出到linux-bridge端口\n\n\n## 具体学习内容:\n\n\n##   1. 包的目的mac跟当前的源mac匹配\n\n\n##   2. 将tunnel号修改为当前的tunnel号\n\n\n##   3. 从当前入口发出\n\novs-ofctl add-flow br-int \ntable=10, priority=1, tun_id=1001100, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]-\nNXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:\n${\nvio1001100_ofport\n}\n\novs-ofctl add-flow br-int \ntable=10, priority=1, tun_id=1234567, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]-\nNXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:\n${\nvio1234567_ofport\n}\n\n\n\n## 其余DROP（可选）\n\novs-ofctl add-flow br-int \ntable=10, priority=0, actions=drop\n\n\n\n\n# table 20\n\n\n## 有学习到规则的数据包，根据规则打上tunnel号并从对应的vtep port发出（动态，不用写规则）\n\n\n\n## 其余扔给table 22处理\n\novs-ofctl add-flow br-int \ntable=20, priority=0, actions=goto_table:22\n\n\n\n\n# table 22\n\n\n## 匹配in_port后打上tunnel号，并从对应的vtep port发出（多条）\n\novs-ofctl add-flow br-int \ntable=22, priority=1, in_port=\n${\nvio1001100_ofport\n}\n, actions=set_tunnel:1001100,output:\n${\nvtep137_ofport\n}\n,\n${\nvtep136_ofport\n}\n\novs-ofctl add-flow br-int \ntable=22, priority=1, in_port=\n${\nvio1234567_ofport\n}\n, actions=set_tunnel:1234567,output:\n${\nvtep137_ofport\n}\n,\n${\nvtep136_ofport\n}\n\n\n\n## 其余DROP\n\novs-ofctl add-flow br-int \ntable=22, priority=0, actions=drop\n\n\n\n\n\n\n\n\nvm.sh\n\n\n点击打开\nip netns del s1-vm5\nip netns del s1-vm6\nip netns del s2-vm5\nip netns del s2-vm6\n\nip netns add s1-vm5\nip link add poi-s1-vm5 \ntype\n veth peer name pii-s1-vm5\nip link \nset\n pii-s1-vm5 netns s1-vm5\nip netns \nexec\n s1-vm5 ip link \nset\n lo up\nip netns \nexec\n s1-vm5 ip addr add \n192\n.168.1.5/24 dev pii-s1-vm5\nip netns \nexec\n s1-vm5 ip link \nset\n pii-s1-vm5 up\nip netns \nexec\n s1-vm5 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s1-vm5 up\nbrctl addif biv-1001100 poi-s1-vm5\n\nip netns add s1-vm6\nip link add poi-s1-vm6 \ntype\n veth peer name pii-s1-vm6\nip link \nset\n pii-s1-vm6 netns s1-vm6\nip netns \nexec\n s1-vm6 ip link \nset\n lo up\nip netns \nexec\n s1-vm6 ip addr add \n192\n.168.1.6/24 dev pii-s1-vm6\nip netns \nexec\n s1-vm6 ip link \nset\n pii-s1-vm6 up\nip netns \nexec\n s1-vm6 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s1-vm6 up\nbrctl addif biv-1001100 poi-s1-vm6\n\nip netns add s2-vm5\nip link add poi-s2-vm5 \ntype\n veth peer name pii-s2-vm5\nip link \nset\n pii-s2-vm5 netns s2-vm5\nip netns \nexec\n s2-vm5 ip link \nset\n lo up\nip netns \nexec\n s2-vm5 ip addr add \n192\n.168.2.5/24 dev pii-s2-vm5\nip netns \nexec\n s2-vm5 ip link \nset\n pii-s2-vm5 up\nip netns \nexec\n s2-vm5 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s2-vm5 up\nbrctl addif biv-1234567 poi-s2-vm5\n\nip netns add s2-vm6\nip link add poi-s2-vm6 \ntype\n veth peer name pii-s2-vm6\nip link \nset\n pii-s2-vm6 netns s2-vm6\nip netns \nexec\n s2-vm6 ip link \nset\n lo up\nip netns \nexec\n s2-vm6 ip addr add \n192\n.168.2.6/24 dev pii-s2-vm6\nip netns \nexec\n s2-vm6 ip link \nset\n pii-s2-vm6 up\nip netns \nexec\n s2-vm6 \necho\n \n1\n \n /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link \nset\n poi-s2-vm6 up\nbrctl addif biv-1234567 poi-s2-vm6", 
            "title": "1. 实验1"
        }, 
        {
            "location": "/test/test1/#_1", 
            "text": "物理图   逻辑图   流表图", 
            "title": "架构图"
        }, 
        {
            "location": "/test/test1/#node-1", 
            "text": "ovs.sh  点击打开 # 删除ovs桥接 \novs-vsctl del-br br-int # 创建ovs桥接 \novs-vsctl add-br br-int # 清空流表 \novs-ofctl del-flows br-int # 创建vtep \novs-vsctl add-port br-int vtep137 --  set  interface vtep137  type = vxlan options:remote_ip = 172 .16.1.137 options:ttl = 64  options:in_key = flow options:out_key = flow\novs-vsctl add-port br-int vtep138 --  set  interface vtep138  type = vxlan options:remote_ip = 172 .16.1.138 options:ttl = 64  options:in_key = flow options:out_key = flow    bridge.sh  点击打开 brctl delbr biv-1001100\nbrctl delbr biv-1234567\n\nbrctl addbr biv-1001100\nip link  set  biv-1001100 up\n\nbrctl addbr biv-1234567\nip link  set  biv-1234567 up    br-to-ovs.sh  点击打开 ip link delete vib-1001100\nip link delete vib-1234567\n\nip link add vib-1001100  type  veth peer name vio-1001100\nbrctl addif biv-1001100 vib-1001100\nip link  set  vib-1001100 up\nip link  set  vio-1001100 up\novs-vsctl add-port br-int vio-1001100\n\nip link add vib-1234567  type  veth peer name vio-1234567\nbrctl addif biv-1234567 vib-1234567\nip link  set  vib-1234567 up\nip link  set  vio-1234567 up\novs-vsctl add-port br-int vio-1234567    openflow.sh  点击打开 # 写openflow规则顺序：  # 1. 从表0开始  # 2. 为每个表之间留一些表，用于今后扩展  # 3. 跳表时候只往高了跳，不往低了跳  # 4. priority=1的写规则，可存在多条；priotity=0的只能有一条，用于其余数据包处理  # 获得openflow端口  vio1001100_ofport = ` ovs-vsctl get interface vio-1001100 ofport `  vio1234567_ofport = ` ovs-vsctl get interface vio-1234567 ofport `  vtep137_ofport = ` ovs-vsctl get interface vtep137 ofport `  vtep138_ofport = ` ovs-vsctl get interface vtep138 ofport `  # table 0  ## 从linux-bridge过来的数据包，扔给table 2处理 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vio1001100_ofport } , actions=goto_table:2 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vio1234567_ofport } , actions=goto_table:2  ## 从vtep过来的数据包，扔给table 10处理 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vtep137_ofport }  actions=goto_table:10 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vtep138_ofport }  actions=goto_table:10  ## 其余DROP \novs-ofctl add-flow br-int  table=0, priority=0, actions=drop  # table 2  ## 单播包，扔给table 20处理 \novs-ofctl add-flow br-int  table=2, priority=1, dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:20  ## 多播和广播包，扔给table 22处理 \novs-ofctl add-flow br-int  table=2, priority=1, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:22  ## 其余DROP \novs-ofctl add-flow br-int  table=2, priority=0, actions=drop  # table 10  ## 学习从vtep过来的数据包，往table 20中添加返程规则，然后输出到linux-bridge端口  ## 具体学习内容:  ##   1. 包的目的mac跟当前的源mac匹配  ##   2. 将tunnel号修改为当前的tunnel号  ##   3. 从当前入口发出 \novs-ofctl add-flow br-int  table=10, priority=1, tun_id=1001100, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]- NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output: ${ vio1001100_ofport } \novs-ofctl add-flow br-int  table=10, priority=1, tun_id=1234567, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]- NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output: ${ vio1234567_ofport }  ## 其余DROP（可选） \novs-ofctl add-flow br-int  table=10, priority=0, actions=drop  # table 20  ## 有学习到规则的数据包，根据规则打上tunnel号并从对应的vtep port发出（动态，不用写规则）  ## 其余扔给table 22处理 \novs-ofctl add-flow br-int  table=20, priority=0, actions=goto_table:22  # table 22  ## 匹配in_port后打上tunnel号，并从对应的vtep port发出（多条） \novs-ofctl add-flow br-int  table=22, priority=1, in_port= ${ vio1001100_ofport } , actions=set_tunnel:1001100,output: ${ vtep137_ofport } , ${ vtep138_ofport } \novs-ofctl add-flow br-int  table=22, priority=1, in_port= ${ vio1234567_ofport } , actions=set_tunnel:1234567,output: ${ vtep137_ofport } , ${ vtep138_ofport }  ## 其余DROP \novs-ofctl add-flow br-int  table=22, priority=0, actions=drop     vm.sh  点击打开 ip netns del s1-vm1\nip netns del s1-vm2\nip netns del s2-vm1\nip netns del s2-vm2\n\nip netns add s1-vm1\nip link add poi-s1-vm1  type  veth peer name pii-s1-vm1\nip link  set  pii-s1-vm1 netns s1-vm1\nip netns  exec  s1-vm1 ip link  set  lo up\nip netns  exec  s1-vm1 ip addr add  192 .168.1.1/24 dev pii-s1-vm1\nip netns  exec  s1-vm1 ip link  set  pii-s1-vm1 up\nip netns  exec  s1-vm1  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s1-vm1 up\nbrctl addif biv-1001100 poi-s1-vm1\n\nip netns add s1-vm2\nip link add poi-s1-vm2  type  veth peer name pii-s1-vm2\nip link  set  pii-s1-vm2 netns s1-vm2\nip netns  exec  s1-vm2 ip link  set  lo up\nip netns  exec  s1-vm2 ip addr add  192 .168.1.2/24 dev pii-s1-vm2\nip netns  exec  s1-vm2 ip link  set  pii-s1-vm2 up\nip netns  exec  s1-vm2  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s1-vm2 up\nbrctl addif biv-1001100 poi-s1-vm2\n\nip netns add s2-vm1\nip link add poi-s2-vm1  type  veth peer name pii-s2-vm1\nip link  set  pii-s2-vm1 netns s2-vm1\nip netns  exec  s2-vm1 ip link  set  lo up\nip netns  exec  s2-vm1 ip addr add  192 .168.2.1/24 dev pii-s2-vm1\nip netns  exec  s2-vm1 ip link  set  pii-s2-vm1 up\nip netns  exec  s2-vm1  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s2-vm1 up\nbrctl addif biv-1234567 poi-s2-vm1\n\nip netns add s2-vm2\nip link add poi-s2-vm2  type  veth peer name pii-s2-vm2\nip link  set  pii-s2-vm2 netns s2-vm2\nip netns  exec  s2-vm2 ip link  set  lo up\nip netns  exec  s2-vm2 ip addr add  192 .168.2.2/24 dev pii-s2-vm2\nip netns  exec  s2-vm2 ip link  set  pii-s2-vm2 up\nip netns  exec  s2-vm2  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s2-vm2 up\nbrctl addif biv-1234567 poi-s2-vm2", 
            "title": "Node 1"
        }, 
        {
            "location": "/test/test1/#node-2", 
            "text": "ovs.sh  点击打开 # 删除ovs桥接 \novs-vsctl del-br br-int # 创建ovs桥接 \novs-vsctl add-br br-int # 清空流表 \novs-ofctl del-flows br-int # 创建vtep \novs-vsctl add-port br-int vtep136 --  set  interface vtep136  type = vxlan options:remote_ip = 172 .16.1.136 options:ttl = 64  options:in_key = flow options:out_key = flow\novs-vsctl add-port br-int vtep138 --  set  interface vtep138  type = vxlan options:remote_ip = 172 .16.1.138 options:ttl = 64  options:in_key = flow options:out_key = flow    bridge.sh  点击打开 brctl delbr biv-1001100\nbrctl delbr biv-1234567\n\nbrctl addbr biv-1001100\nip link  set  biv-1001100 up\n\nbrctl addbr biv-1234567\nip link  set  biv-1234567 up    br-to-ovs.sh  点击打开 ip link delete vib-1001100\nip link delete vib-1234567\n\nip link add vib-1001100  type  veth peer name vio-1001100\nbrctl addif biv-1001100 vib-1001100\nip link  set  vib-1001100 up\nip link  set  vio-1001100 up\novs-vsctl add-port br-int vio-1001100\n\nip link add vib-1234567  type  veth peer name vio-1234567\nbrctl addif biv-1234567 vib-1234567\nip link  set  vib-1234567 up\nip link  set  vio-1234567 up\novs-vsctl add-port br-int vio-1234567    openflow.sh  点击打开 # 写openflow规则顺序：  # 1. 从表0开始  # 2. 为每个表之间留一些表，用于今后扩展  # 3. 跳表时候只往高了跳，不往低了跳  # 4. priority=1的写规则，可存在多条；priotity=0的只能有一条，用于其余数据包处理  # 获得openflow端口  vio1001100_ofport = ` ovs-vsctl get interface vio-1001100 ofport `  vio1234567_ofport = ` ovs-vsctl get interface vio-1234567 ofport `  vtep136_ofport = ` ovs-vsctl get interface vtep136 ofport `  vtep138_ofport = ` ovs-vsctl get interface vtep138 ofport `  # table 0  ## 从linux-bridge过来的数据包，扔给table 2处理 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vio1001100_ofport } , actions=goto_table:2 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vio1234567_ofport } , actions=goto_table:2  ## 从vtep过来的数据包，扔给table 10处理 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vtep136_ofport }  actions=goto_table:10 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vtep138_ofport }  actions=goto_table:10  ## 其余DROP \novs-ofctl add-flow br-int  table=0, priority=0, actions=drop  # table 2  ## 单播包，扔给table 20处理 \novs-ofctl add-flow br-int  table=2, priority=1, dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:20  ## 多播和广播包，扔给table 22处理 \novs-ofctl add-flow br-int  table=2, priority=1, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:22  ## 其余DROP \novs-ofctl add-flow br-int  table=2, priority=0, actions=drop  # table 10  ## 学习从vtep过来的数据包，往table 20中添加返程规则，然后输出到linux-bridge端口  ## 具体学习内容:  ##   1. 包的目的mac跟当前的源mac匹配  ##   2. 将tunnel号修改为当前的tunnel号  ##   3. 从当前入口发出 \novs-ofctl add-flow br-int  table=10, priority=1, tun_id=1001100, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]- NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output: ${ vio1001100_ofport } \novs-ofctl add-flow br-int  table=10, priority=1, tun_id=1234567, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]- NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output: ${ vio1234567_ofport }  ## 其余DROP（可选） \novs-ofctl add-flow br-int  table=10, priority=0, actions=drop  # table 20  ## 有学习到规则的数据包，根据规则打上tunnel号并从对应的vtep port发出（动态，不用写规则）  ## 其余扔给table 22处理 \novs-ofctl add-flow br-int  table=20, priority=0, actions=goto_table:22  # table 22  ## 匹配in_port后打上tunnel号，并从对应的vtep port发出（多条） \novs-ofctl add-flow br-int  table=22, priority=1, in_port= ${ vio1001100_ofport } , actions=set_tunnel:1001100,output: ${ vtep136_ofport } , ${ vtep138_ofport } \novs-ofctl add-flow br-int  table=22, priority=1, in_port= ${ vio1234567_ofport } , actions=set_tunnel:1234567,output: ${ vtep136_ofport } , ${ vtep138_ofport }  ## 其余DROP \novs-ofctl add-flow br-int  table=22, priority=0, actions=drop     vm.sh  点击打开 ip netns del s1-vm3\nip netns del s1-vm4\nip netns del s2-vm3\nip netns del s2-vm4\n\nip netns add s1-vm3\nip link add poi-s1-vm3  type  veth peer name pii-s1-vm3\nip link  set  pii-s1-vm3 netns s1-vm3\nip netns  exec  s1-vm3 ip link  set  lo up\nip netns  exec  s1-vm3 ip addr add  192 .168.1.3/24 dev pii-s1-vm3\nip netns  exec  s1-vm3 ip link  set  pii-s1-vm3 up\nip netns  exec  s1-vm3  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s1-vm3 up\nbrctl addif biv-1001100 poi-s1-vm3\n\nip netns add s1-vm4\nip link add poi-s1-vm4  type  veth peer name pii-s1-vm4\nip link  set  pii-s1-vm4 netns s1-vm4\nip netns  exec  s1-vm4 ip link  set  lo up\nip netns  exec  s1-vm4 ip addr add  192 .168.1.4/24 dev pii-s1-vm4\nip netns  exec  s1-vm4 ip link  set  pii-s1-vm4 up\nip netns  exec  s1-vm4  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s1-vm4 up\nbrctl addif biv-1001100 poi-s1-vm4\n\nip netns add s2-vm3\nip link add poi-s2-vm3  type  veth peer name pii-s2-vm3\nip link  set  pii-s2-vm3 netns s2-vm3\nip netns  exec  s2-vm3 ip link  set  lo up\nip netns  exec  s2-vm3 ip addr add  192 .168.2.3/24 dev pii-s2-vm3\nip netns  exec  s2-vm3 ip link  set  pii-s2-vm3 up\nip netns  exec  s2-vm3  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s2-vm3 up\nbrctl addif biv-1234567 poi-s2-vm3\n\nip netns add s2-vm4\nip link add poi-s2-vm4  type  veth peer name pii-s2-vm4\nip link  set  pii-s2-vm4 netns s2-vm4\nip netns  exec  s2-vm4 ip link  set  lo up\nip netns  exec  s2-vm4 ip addr add  192 .168.2.4/24 dev pii-s2-vm4\nip netns  exec  s2-vm4 ip link  set  pii-s2-vm4 up\nip netns  exec  s2-vm4  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s2-vm4 up\nbrctl addif biv-1234567 poi-s2-vm4", 
            "title": "Node 2"
        }, 
        {
            "location": "/test/test1/#node-3", 
            "text": "ovs.sh  点击打开 # 删除ovs桥接 \novs-vsctl del-br br-int # 创建ovs桥接 \novs-vsctl add-br br-int # 清空流表 \novs-ofctl del-flows br-int # 创建vtep \novs-vsctl add-port br-int vtep137 --  set  interface vtep137  type = vxlan options:remote_ip = 172 .16.1.137 options:ttl = 64  options:in_key = flow options:out_key = flow\novs-vsctl add-port br-int vtep136 --  set  interface vtep136  type = vxlan options:remote_ip = 172 .16.1.136 options:ttl = 64  options:in_key = flow options:out_key = flow    bridge.sh  点击打开 brctl delbr biv-1001100\nbrctl delbr biv-1234567\n\nbrctl addbr biv-1001100\nip link  set  biv-1001100 up\n\nbrctl addbr biv-1234567\nip link  set  biv-1234567 up    br-to-ovs.sh  点击打开 ip link delete vib-1001100\nip link delete vib-1234567\n\nip link add vib-1001100  type  veth peer name vio-1001100\nbrctl addif biv-1001100 vib-1001100\nip link  set  vib-1001100 up\nip link  set  vio-1001100 up\novs-vsctl add-port br-int vio-1001100\n\nip link add vib-1234567  type  veth peer name vio-1234567\nbrctl addif biv-1234567 vib-1234567\nip link  set  vib-1234567 up\nip link  set  vio-1234567 up\novs-vsctl add-port br-int vio-1234567    openflow.sh  点击打开 # 写openflow规则顺序：  # 1. 从表0开始  # 2. 为每个表之间留一些表，用于今后扩展  # 3. 跳表时候只往高了跳，不往低了跳  # 4. priority=1的写规则，可存在多条；priotity=0的只能有一条，用于其余数据包处理  # 获得openflow端口  vio1001100_ofport = ` ovs-vsctl get interface vio-1001100 ofport `  vio1234567_ofport = ` ovs-vsctl get interface vio-1234567 ofport `  vtep137_ofport = ` ovs-vsctl get interface vtep137 ofport `  vtep136_ofport = ` ovs-vsctl get interface vtep136 ofport `  # table 0  ## 从linux-bridge过来的数据包，扔给table 2处理 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vio1001100_ofport } , actions=goto_table:2 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vio1234567_ofport } , actions=goto_table:2  ## 从vtep过来的数据包，扔给table 10处理 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vtep137_ofport }  actions=goto_table:10 \novs-ofctl add-flow br-int  table=0, priority=1, in_port= ${ vtep136_ofport }  actions=goto_table:10  ## 其余DROP \novs-ofctl add-flow br-int  table=0, priority=0, actions=drop  # table 2  ## 单播包，扔给table 20处理 \novs-ofctl add-flow br-int  table=2, priority=1, dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:20  ## 多播和广播包，扔给table 22处理 \novs-ofctl add-flow br-int  table=2, priority=1, dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=goto_table:22  ## 其余DROP \novs-ofctl add-flow br-int  table=2, priority=0, actions=drop  # table 10  ## 学习从vtep过来的数据包，往table 20中添加返程规则，然后输出到linux-bridge端口  ## 具体学习内容:  ##   1. 包的目的mac跟当前的源mac匹配  ##   2. 将tunnel号修改为当前的tunnel号  ##   3. 从当前入口发出 \novs-ofctl add-flow br-int  table=10, priority=1, tun_id=1001100, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]- NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output: ${ vio1001100_ofport } \novs-ofctl add-flow br-int  table=10, priority=1, tun_id=1234567, actions=learn(table=20,hard_timeout=300,priority=1,NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:NXM_NX_TUN_ID[]- NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output: ${ vio1234567_ofport }  ## 其余DROP（可选） \novs-ofctl add-flow br-int  table=10, priority=0, actions=drop  # table 20  ## 有学习到规则的数据包，根据规则打上tunnel号并从对应的vtep port发出（动态，不用写规则）  ## 其余扔给table 22处理 \novs-ofctl add-flow br-int  table=20, priority=0, actions=goto_table:22  # table 22  ## 匹配in_port后打上tunnel号，并从对应的vtep port发出（多条） \novs-ofctl add-flow br-int  table=22, priority=1, in_port= ${ vio1001100_ofport } , actions=set_tunnel:1001100,output: ${ vtep137_ofport } , ${ vtep136_ofport } \novs-ofctl add-flow br-int  table=22, priority=1, in_port= ${ vio1234567_ofport } , actions=set_tunnel:1234567,output: ${ vtep137_ofport } , ${ vtep136_ofport }  ## 其余DROP \novs-ofctl add-flow br-int  table=22, priority=0, actions=drop     vm.sh  点击打开 ip netns del s1-vm5\nip netns del s1-vm6\nip netns del s2-vm5\nip netns del s2-vm6\n\nip netns add s1-vm5\nip link add poi-s1-vm5  type  veth peer name pii-s1-vm5\nip link  set  pii-s1-vm5 netns s1-vm5\nip netns  exec  s1-vm5 ip link  set  lo up\nip netns  exec  s1-vm5 ip addr add  192 .168.1.5/24 dev pii-s1-vm5\nip netns  exec  s1-vm5 ip link  set  pii-s1-vm5 up\nip netns  exec  s1-vm5  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s1-vm5 up\nbrctl addif biv-1001100 poi-s1-vm5\n\nip netns add s1-vm6\nip link add poi-s1-vm6  type  veth peer name pii-s1-vm6\nip link  set  pii-s1-vm6 netns s1-vm6\nip netns  exec  s1-vm6 ip link  set  lo up\nip netns  exec  s1-vm6 ip addr add  192 .168.1.6/24 dev pii-s1-vm6\nip netns  exec  s1-vm6 ip link  set  pii-s1-vm6 up\nip netns  exec  s1-vm6  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s1-vm6 up\nbrctl addif biv-1001100 poi-s1-vm6\n\nip netns add s2-vm5\nip link add poi-s2-vm5  type  veth peer name pii-s2-vm5\nip link  set  pii-s2-vm5 netns s2-vm5\nip netns  exec  s2-vm5 ip link  set  lo up\nip netns  exec  s2-vm5 ip addr add  192 .168.2.5/24 dev pii-s2-vm5\nip netns  exec  s2-vm5 ip link  set  pii-s2-vm5 up\nip netns  exec  s2-vm5  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s2-vm5 up\nbrctl addif biv-1234567 poi-s2-vm5\n\nip netns add s2-vm6\nip link add poi-s2-vm6  type  veth peer name pii-s2-vm6\nip link  set  pii-s2-vm6 netns s2-vm6\nip netns  exec  s2-vm6 ip link  set  lo up\nip netns  exec  s2-vm6 ip addr add  192 .168.2.6/24 dev pii-s2-vm6\nip netns  exec  s2-vm6 ip link  set  pii-s2-vm6 up\nip netns  exec  s2-vm6  echo   1    /proc/sys/net/ipv6/conf/all/disable_ipv6\nip link  set  poi-s2-vm6 up\nbrctl addif biv-1234567 poi-s2-vm6", 
            "title": "Node 3"
        }, 
        {
            "location": "/test/stress/", 
            "text": "环境说明\n\n\n\n\n服务器：Dell R730，网卡为板载集成电口万兆（支持udp offload），os为centos 7.3\n\n\n交换机：Dell万兆交换机\n\n\nkvm：qemu-kvm 1.5.3，网卡virtio，os为centos 7.3 4核8G\n\n\n内核参数：物理机、netns、kvm均不改变任何内核参数，并且iptables、ebtables、selinux均处于disable状态\n\n\n测试方法：使用iperf分别测试tcp和udp（只测试单播），每一个测试完成后均重启物理机\n\n\n测试命令：\n\n\n\n\n\n\ntcp\n\n\nclient: iperf -b 10G -t 300 -P 3 -c 目标ip\n\n\nserver: iperf -s\n\n\n\n\n\n\nudp\n\n\nclient: iperf -u -b 10G -t 300 -P 3 -c 目标ip\n\n\nserver: iperf -u -s\n\n\n\n\n\n\n测试结果：client为平均每秒出站流量，server为平均每秒入站流量\n\n\n同宿主\n\n\n\n\nbridge\n\n\n\n\n\n\nns - ns（veth）\n\n\ntcp:\n    client 10.7Gb/s\n    server 10.7Gb/s\nudp:\n    client 4.93Gb/s\n    server 4.93Gb/s\n\n\n\n\n环境\nbrctl addbr br1\nip link set br1 up\nip netns add ns1\nip netns add ns2\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns2-veth-in netns ns2\nip link set ns1-veth-out up\nip link set ns2-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns2 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\nbrctl addif br1 ns1-veth-out\nbrctl addif br1 ns2-veth-out\n\n\n\n\n\n\n\nkvm - kvm\n\n\ntcp:\n    client 5.57Gb/s\n    server 5.57Gb/s\nudp:\n    client 5.58Gb/s\n    server 5.39Gb/s\n\n\n\n\n\n\n\n\novs\n\n\n\n\n\n\nns - ns（veth）\n\n\ntcp:\n    client 10.7Gb/s\n    server 10.7Gb/s\nudp:\n    client 3.85Gb/s\n    server 3.85Gb/s\n\n\n\n\n环境\novs-vsctl add-br ovsbr\nip netns add ns1\nip netns add ns2\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns2-veth-in netns ns2\nip link set ns1-veth-out up\nip link set ns2-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns2 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\novs-vsctl add-port ovsbr ns1-veth-out\novs-vsctl add-port ovsbr ns2-veth-out\n\n\n\n\n\n\n\nns - ns（patch-port）\n\n\ntcp:\n    client 10.7Gb/s\n    server 10.7Gb/s\nudp:\n    client 3.91Gb/s\n    server 3.91Gb/s\n\n\n\n\n环境\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr ns1 -- set interface ns1 type=internal\novs-vsctl add-port ovsbr ns2 -- set interface ns2 type=internal\nip netns add ns1\nip netns add ns2\nip link set ns1 netns ns1\nip link set ns2 netns ns2\nip netns exec ns1 ip link set lo up\nip netns exec ns2 ip link set lo up\nip netns exec ns1 ifconfig ns1 192.168.1.1 netmask 255.255.255.0 up\nip netns exec ns2 ifconfig ns2 192.168.1.2 netmask 255.255.255.0 up\n\n\n\n\n\n\n\nkvm - kvm\n\n\ntcp:\n    client 5.83Gb/s\n    server 5.83Gb/s\nudp:\n    client 5.33Gb/s\n    server 5.18Gb/s\n\n\n\n\nxml配置\ninterface\n \ntype=\nbridge\n\n  \nmac\n \naddress=\n52:54:00:c8:3b:ea\n/\n\n  \nsource\n \nbridge=\novsbr\n/\n\n\n  \nvirtualport\n \ntype=\nopenvswitch\n/\n\n\n  \ntarget\n \ndev=\nvmeth0-vm1\n/\n\n  \nmodel\n \ntype=\nvirtio\n/\n\n\n/interface\n\n\n\n\n\n\n\n\n不同宿主\n\n\n\n\n基准\n\n\n\n\n\n\nem1 - em1\n\n\ntcp:\n    client 7.02Gb/s\n    server 7.02Gb/s\nudp:\n    client 8.14Gb/s\n    server 8.08Gb/s\n\n\n\n\n\n\n\n\nbridge-\nem1 - em1\n-bridge（bridge为3层）\n\n\ntcp:\n    client 6.62Gb/s\n    server 6.62Gb/s\nudp:\n    client 8.19Gb/s\n    server 7.94Gb/s\n\n\n\n\n\n\n\n\n无封装\n\n\nbridge\n\n\n\n\n\n\nns - ns（veth）\n\n\ntcp:\n    client 6.24Gb/s\n    server 6.24Gb/s\nudp:\n    client 6.89Gb/s\n    server 6.88Gb/s\n\n\n\n\n环境\nHost1:\nbrctl addbr br1\nip link set br1 up\nifconfig em1 0.0.0.0\nbrctl addif br1 em1\nip netns add ns1\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns1-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\nbrctl addif br1 ns1-veth-out\n\nHost2:\nbrctl addbr br1\nip link set br1 up\nifconfig em1 0.0.0.0\nbrctl addif br1 em1\nip netns add ns2\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns2-veth-in netns ns2\nip link set ns2-veth-out up\nip netns exec ns2 ip link set lo up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\nbrctl addif br1 ns2-veth-out\n\n\n\n\n\n\n\nkvm - kvm\n\n\ntcp:\n    client 5.94Gb/s\n    server 5.94Gb/s\nudp:\n    client 6.41Gb/s\n    server 4.93Gb/s\n\n\n\n\n\n\n\n\novs\n\n\n\n\n\n\nns - ns（veth）\n\n\ntcp:\n    client 6.09Gb/s\n    server 6.09Gb/s\nudp:\n    client 5.94Gb/s\n    server 5.60Gb/s\n\n\n\n\n??? note “环境”\n    \nHost1:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\nip netns add ns1\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns1-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\novs-vsctl add-port ovsbr ns1-veth-out\n\nHost2:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\nip netns add ns2\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns2-veth-in netns ns2\nip link set ns2-veth-out up\nip netns exec ns2 ip link set lo up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\novs-vsctl add-port ovsbr ns2-veth-out\n\n\n\n\n\n\n\nns - ns（patch-port）\n\n\ntcp:\n    client 6.28Gb/s\n    server 6.28Gb/s\nudp:\n    client 7.05Gb/s\n    server 7.04Gb/s\n\n\n\n\n环境\nHost1:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\novs-vsctl add-port ovsbr ns1 -- set interface ns1 type=internal\nip netns add ns1\nip link set ns1 netns ns1\nip netns exec ns1 ip link set lo up\nip netns exec ns1 ifconfig ns1 192.168.1.1 netmask 255.255.255.0 up\n\nHost2:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\novs-vsctl add-port ovsbr ns2 -- set interface ns2 type=internal\nip netns add ns2\nip link set ns2 netns ns2\nip netns exec ns2 ip link set lo up\nip netns exec ns2 ifconfig ns2 192.168.1.2 netmask 255.255.255.0 up\n\n\n\n\n\n\n\nkvm - kvm\n\n\ntcp:\n    client 5.50Gb/s\n    server 5.50Gb/s\nudp:\n    client 8.50Gb/s\n    server 5.90Gb/s\n\n\n\n\n\n\n\n\nvxlan封装\n\n\nbridge\n\n\n\n\n\n\nns - ns（veth）\n\n\n\n\n\n\n\n\n\n\n\nkvm - kvm\n\n\n\n\n\n\n\n\n\n\n\novs\n\n\nem1 - - - vtep - ovsbr\n\n\n\n\n\n\nns - ns（veth）\n\n\n\n\n\n\n\n\n\n\n\nns - ns（patch-port）\n\n\n\n\n\n\n\n\n\n\n\nkvm - kvm\n\n\n\n\n\n\n\n\n\n\n\novs-bridge\n\n\nem1 - - - vtep - ovsbr - bridge\n\n\n\n\n\n\nns - ns（veth）\n\n\n\n\n\n\n\n\n\n\n\nns - ns（patch-port）\n\n\n\n\n\n\n\n\n\n\n\nkvm - kvm\n\n\n\n\n\n\n\n\n\n\n\n结论\n\n\n\n\n性能排行\n\n\nbridge和ovs性能对比", 
            "title": "2. 性能测试"
        }, 
        {
            "location": "/test/stress/#_1", 
            "text": "服务器：Dell R730，网卡为板载集成电口万兆（支持udp offload），os为centos 7.3  交换机：Dell万兆交换机  kvm：qemu-kvm 1.5.3，网卡virtio，os为centos 7.3 4核8G  内核参数：物理机、netns、kvm均不改变任何内核参数，并且iptables、ebtables、selinux均处于disable状态  测试方法：使用iperf分别测试tcp和udp（只测试单播），每一个测试完成后均重启物理机  测试命令：    tcp  client: iperf -b 10G -t 300 -P 3 -c 目标ip  server: iperf -s    udp  client: iperf -u -b 10G -t 300 -P 3 -c 目标ip  server: iperf -u -s    测试结果：client为平均每秒出站流量，server为平均每秒入站流量", 
            "title": "环境说明"
        }, 
        {
            "location": "/test/stress/#_2", 
            "text": "", 
            "title": "同宿主"
        }, 
        {
            "location": "/test/stress/#bridge", 
            "text": "ns - ns（veth）  tcp:\n    client 10.7Gb/s\n    server 10.7Gb/s\nudp:\n    client 4.93Gb/s\n    server 4.93Gb/s  环境 brctl addbr br1\nip link set br1 up\nip netns add ns1\nip netns add ns2\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns2-veth-in netns ns2\nip link set ns1-veth-out up\nip link set ns2-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns2 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\nbrctl addif br1 ns1-veth-out\nbrctl addif br1 ns2-veth-out    kvm - kvm  tcp:\n    client 5.57Gb/s\n    server 5.57Gb/s\nudp:\n    client 5.58Gb/s\n    server 5.39Gb/s", 
            "title": "bridge"
        }, 
        {
            "location": "/test/stress/#ovs", 
            "text": "ns - ns（veth）  tcp:\n    client 10.7Gb/s\n    server 10.7Gb/s\nudp:\n    client 3.85Gb/s\n    server 3.85Gb/s  环境 ovs-vsctl add-br ovsbr\nip netns add ns1\nip netns add ns2\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns2-veth-in netns ns2\nip link set ns1-veth-out up\nip link set ns2-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns2 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\novs-vsctl add-port ovsbr ns1-veth-out\novs-vsctl add-port ovsbr ns2-veth-out    ns - ns（patch-port）  tcp:\n    client 10.7Gb/s\n    server 10.7Gb/s\nudp:\n    client 3.91Gb/s\n    server 3.91Gb/s  环境 ovs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr ns1 -- set interface ns1 type=internal\novs-vsctl add-port ovsbr ns2 -- set interface ns2 type=internal\nip netns add ns1\nip netns add ns2\nip link set ns1 netns ns1\nip link set ns2 netns ns2\nip netns exec ns1 ip link set lo up\nip netns exec ns2 ip link set lo up\nip netns exec ns1 ifconfig ns1 192.168.1.1 netmask 255.255.255.0 up\nip netns exec ns2 ifconfig ns2 192.168.1.2 netmask 255.255.255.0 up    kvm - kvm  tcp:\n    client 5.83Gb/s\n    server 5.83Gb/s\nudp:\n    client 5.33Gb/s\n    server 5.18Gb/s  xml配置 interface   type= bridge \n   mac   address= 52:54:00:c8:3b:ea / \n   source   bridge= ovsbr /     virtualport   type= openvswitch /     target   dev= vmeth0-vm1 / \n   model   type= virtio /  /interface", 
            "title": "ovs"
        }, 
        {
            "location": "/test/stress/#_3", 
            "text": "", 
            "title": "不同宿主"
        }, 
        {
            "location": "/test/stress/#_4", 
            "text": "em1 - em1  tcp:\n    client 7.02Gb/s\n    server 7.02Gb/s\nudp:\n    client 8.14Gb/s\n    server 8.08Gb/s    bridge- em1 - em1 -bridge（bridge为3层）  tcp:\n    client 6.62Gb/s\n    server 6.62Gb/s\nudp:\n    client 8.19Gb/s\n    server 7.94Gb/s", 
            "title": "基准"
        }, 
        {
            "location": "/test/stress/#_5", 
            "text": "", 
            "title": "无封装"
        }, 
        {
            "location": "/test/stress/#bridge_1", 
            "text": "ns - ns（veth）  tcp:\n    client 6.24Gb/s\n    server 6.24Gb/s\nudp:\n    client 6.89Gb/s\n    server 6.88Gb/s  环境 Host1:\nbrctl addbr br1\nip link set br1 up\nifconfig em1 0.0.0.0\nbrctl addif br1 em1\nip netns add ns1\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns1-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\nbrctl addif br1 ns1-veth-out\n\nHost2:\nbrctl addbr br1\nip link set br1 up\nifconfig em1 0.0.0.0\nbrctl addif br1 em1\nip netns add ns2\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns2-veth-in netns ns2\nip link set ns2-veth-out up\nip netns exec ns2 ip link set lo up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\nbrctl addif br1 ns2-veth-out    kvm - kvm  tcp:\n    client 5.94Gb/s\n    server 5.94Gb/s\nudp:\n    client 6.41Gb/s\n    server 4.93Gb/s", 
            "title": "bridge"
        }, 
        {
            "location": "/test/stress/#ovs_1", 
            "text": "ns - ns（veth）  tcp:\n    client 6.09Gb/s\n    server 6.09Gb/s\nudp:\n    client 5.94Gb/s\n    server 5.60Gb/s  ??? note “环境”\n     Host1:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\nip netns add ns1\nip link add ns1-veth-in type veth peer name ns1-veth-out\nip link set ns1-veth-in netns ns1\nip link set ns1-veth-out up\nip netns exec ns1 ip link set lo up\nip netns exec ns1 ifconfig ns1-veth-in 192.168.1.1 netmask 255.255.255.0 up\novs-vsctl add-port ovsbr ns1-veth-out\n\nHost2:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\nip netns add ns2\nip link add ns2-veth-in type veth peer name ns2-veth-out\nip link set ns2-veth-in netns ns2\nip link set ns2-veth-out up\nip netns exec ns2 ip link set lo up\nip netns exec ns2 ifconfig ns2-veth-in 192.168.1.2 netmask 255.255.255.0 up\novs-vsctl add-port ovsbr ns2-veth-out    ns - ns（patch-port）  tcp:\n    client 6.28Gb/s\n    server 6.28Gb/s\nudp:\n    client 7.05Gb/s\n    server 7.04Gb/s  环境 Host1:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\novs-vsctl add-port ovsbr ns1 -- set interface ns1 type=internal\nip netns add ns1\nip link set ns1 netns ns1\nip netns exec ns1 ip link set lo up\nip netns exec ns1 ifconfig ns1 192.168.1.1 netmask 255.255.255.0 up\n\nHost2:\novs-vsctl add-br ovsbr\novs-vsctl add-port ovsbr em1\novs-vsctl add-port ovsbr ns2 -- set interface ns2 type=internal\nip netns add ns2\nip link set ns2 netns ns2\nip netns exec ns2 ip link set lo up\nip netns exec ns2 ifconfig ns2 192.168.1.2 netmask 255.255.255.0 up    kvm - kvm  tcp:\n    client 5.50Gb/s\n    server 5.50Gb/s\nudp:\n    client 8.50Gb/s\n    server 5.90Gb/s", 
            "title": "ovs"
        }, 
        {
            "location": "/test/stress/#vxlan", 
            "text": "", 
            "title": "vxlan封装"
        }, 
        {
            "location": "/test/stress/#bridge_2", 
            "text": "ns - ns（veth）      kvm - kvm", 
            "title": "bridge"
        }, 
        {
            "location": "/test/stress/#ovs_2", 
            "text": "em1 - - - vtep - ovsbr    ns - ns（veth）      ns - ns（patch-port）      kvm - kvm", 
            "title": "ovs"
        }, 
        {
            "location": "/test/stress/#ovs-bridge", 
            "text": "em1 - - - vtep - ovsbr - bridge    ns - ns（veth）      ns - ns（patch-port）      kvm - kvm", 
            "title": "ovs-bridge"
        }, 
        {
            "location": "/test/stress/#_6", 
            "text": "", 
            "title": "结论"
        }, 
        {
            "location": "/test/stress/#_7", 
            "text": "", 
            "title": "性能排行"
        }, 
        {
            "location": "/test/stress/#bridgeovs", 
            "text": "", 
            "title": "bridge和ovs性能对比"
        }, 
        {
            "location": "/appendix/doc/", 
            "text": "ovs\n\n\n\n\nhttp://blog.csdn.net/sqx2011/article/details/39344869\n\n\n\n\nopenflow\n\n\n\n\n\n\nhttps://www.ibm.com/developerworks/cn/cloud/library/1401_zhaoyi_openswitch/index.html\n\n\n\n\n\n\nhttp://www.rendoumi.com/open-vswitchzhong-ovs-ofctlde-xiang-xi-yong-fa/\n\n\n\n\n\n\novn\n\n\n\n\n\n\nhttp://www.sdnlab.com/18600.html\n\n\n\n\n\n\nhttp://blog.csdn.net/zhengmx100/article/details/71698641\n\n\n\n\n\n\nmanpage\n\n\n\n\novs-vsctl的options：man ovs-vswitchd.conf.db\n\n\novs-ofctl配置流表的actions：man ovs-ofctl\n\n\nopenflow流表匹配参数：man ovs-fields", 
            "title": "1. 参考资料"
        }, 
        {
            "location": "/appendix/doc/#manpage", 
            "text": "ovs-vsctl的options：man ovs-vswitchd.conf.db  ovs-ofctl配置流表的actions：man ovs-ofctl  openflow流表匹配参数：man ovs-fields", 
            "title": "manpage"
        }, 
        {
            "location": "/appendix/traffic/", 
            "text": "在ovs里，对port只有egress限速，对interface只有ingress限速\n\n\n参考：\nhttp://openvswitch.org/support/dist-docs/ovs-vswitchd.conf.db.5.html\n\n\ningress_policing_rate就是带宽入口限速，超过的丢包处理\n\n\ningress_policing_burst 在ingress_policing_rate之上的入口突发流量限制，该值最少也要等于该interface的MTU值，最好设置为ingress_policing_rate的\n=10%，建议为10%（对TCP很重要，TCP需要对丢包作出反应，而且设置为10%后tcp流量的上限才会更接近ingress_policing_rate值）", 
            "title": "2. ovs数据流量及限速"
        }, 
        {
            "location": "/appendix/nxm/", 
            "text": "The OpenFlow 1.2 format, called OXM (OpenFlow  Extensible  Match),  was modeled  closely  on  an  extension  to OpenFlow 1.0 introduced in Open vSwitch 1.1 called NXM (Nicira Extended Match)\n\n\nman ovs-fields", 
            "title": "3. NXM"
        }, 
        {
            "location": "/appendix/neutron/", 
            "text": "https://github.com/yeasy/openstack_understand_Neutron\n\n\npdf文档已放入本站附件中，\n点击下载\n\n\n\n\n\n\nhttp://blog.sina.com.cn/s/blog_6de3aa8a0102uy3t.html", 
            "title": "4. Neutron流表分析"
        }, 
        {
            "location": "/appendix/mac_mask/", 
            "text": "ovs官方解释\n\n\n\n\nman ovs-fields\b\n\n\nOpen vSwitch 1.8 and later support arbitrary masks for source and/or destination. Earlier versions only support masking the destination with the following masks:\n\n       01:00:00:00:00:00\n              Match  only  the  multicast  bit.  Thus,  dl_dst=01:00:00:00:00:00/01:00:00:00:00:00  matches  all  multicast  (including  broadcast)  Ethernet  packets,  and\n              dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 matches all unicast Ethernet packets.\n\n       fe:ff:ff:ff:ff:ff\n              Match all bits except the multicast bit. This is probably not useful.\n\n       ff:ff:ff:ff:ff:ff\n              Exact match (equivalent to omitting the mask).\n\n       00:00:00:00:00:00\n              Wildcard all bits (equivalent to dl_dst=*).\n\n\n\n\n单播、多播、广播\n\n\n\n\n\n\n\n\n单播: 最左边第一个字节的最后一个bit为0\n\n\nxxxxxxx0:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx\n\n\n可以用\n00:00:00:00:00:00/01:00:00:00:00:00\n来表示\n\n\n\n\n\n\n多播: 最左边第一个字节的最后一个bit为1，当所有bit都为1就是广播，即多播包括广播，就像正方形属于长方形，但正方形是独特的长方形，多播就像是长方形，广播就像是正方形\n\n\nxxxxxxx1:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx\n\n\n可以用\n01:00:00:00:00:00/01:00:00:00:00:00\n来表示，但不是只能这么表示，只要掩码里为0对应到的mac可以为任何数，即也可以写成\na1:bb:cc:dd:ee:ff/01:00:00:00:00:00\n，或者\n11:1b:cc:dd:ee:ff/11:10:08:00:00:00\n，都是可以的\n\n\n\n\n\n\n广播: 所有bit均为1，因此就是\nff:ff:ff:ff:ff:ff/ff:ff:ff:ff:ff:ff\n\n\n\n\n\n\n如果要匹配具体的mac地址，就把掩码写成\nff:ff:ff:ff:ff:ff\n即可（如果不写掩码，默认就是全f）\n\n\n注意：如果想只匹配多播，但不包含广播，没有办法通过掩码做到，只能在写条目规则时候先匹配广播，再匹配多播\n\n\n掩码匹配算法详解\n\n\n\n\n例如\n11:1b:cc:dd:ee:ff/11:10:08:00:00:00\n表示\n\n\n地址\n11:1b:cc:dd:ee:ff\n -\n 二进制为\n00010001:00011011:11001100:11011101:11101110:11111111\n\n\n掩码\n11:10:08:00:00:00\n -\n 二进制为\n00010001:00010000:00001000:00000000:00000000:00000000\n\n\n掩码中为1的，对应到地址的bit不变，掩码中为0的，对应到地址的bit可以为1也可为0，和ip/netmask的算法是类似的，因此这个例子中，可以表示的范围是：\n\n\n最小：\n00010001:00010000:00001000:00000000:00000000:00000000\n\n\n最大：\n11111111:11111111:11111111:11111111:11111111:11111111\n\n\n转换成16进制，则是：\n\n\n从\n11:10:08:00:00:00\n到\nff:ff:ff:ff:ff:ff\n\n\n\n\nWarning\n\n\n这个例子算出来的最小地址刚好和掩码一样，这只是个巧合", 
            "title": "5. MAC地址掩码"
        }, 
        {
            "location": "/appendix/mac_mask/#ovs", 
            "text": "man ovs-fields\b  Open vSwitch 1.8 and later support arbitrary masks for source and/or destination. Earlier versions only support masking the destination with the following masks:\n\n       01:00:00:00:00:00\n              Match  only  the  multicast  bit.  Thus,  dl_dst=01:00:00:00:00:00/01:00:00:00:00:00  matches  all  multicast  (including  broadcast)  Ethernet  packets,  and\n              dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 matches all unicast Ethernet packets.\n\n       fe:ff:ff:ff:ff:ff\n              Match all bits except the multicast bit. This is probably not useful.\n\n       ff:ff:ff:ff:ff:ff\n              Exact match (equivalent to omitting the mask).\n\n       00:00:00:00:00:00\n              Wildcard all bits (equivalent to dl_dst=*).", 
            "title": "ovs官方解释"
        }, 
        {
            "location": "/appendix/mac_mask/#_1", 
            "text": "单播: 最左边第一个字节的最后一个bit为0  xxxxxxx0:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx  可以用 00:00:00:00:00:00/01:00:00:00:00:00 来表示    多播: 最左边第一个字节的最后一个bit为1，当所有bit都为1就是广播，即多播包括广播，就像正方形属于长方形，但正方形是独特的长方形，多播就像是长方形，广播就像是正方形  xxxxxxx1:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx:xxxxxxxx  可以用 01:00:00:00:00:00/01:00:00:00:00:00 来表示，但不是只能这么表示，只要掩码里为0对应到的mac可以为任何数，即也可以写成 a1:bb:cc:dd:ee:ff/01:00:00:00:00:00 ，或者 11:1b:cc:dd:ee:ff/11:10:08:00:00:00 ，都是可以的    广播: 所有bit均为1，因此就是 ff:ff:ff:ff:ff:ff/ff:ff:ff:ff:ff:ff    如果要匹配具体的mac地址，就把掩码写成 ff:ff:ff:ff:ff:ff 即可（如果不写掩码，默认就是全f）  注意：如果想只匹配多播，但不包含广播，没有办法通过掩码做到，只能在写条目规则时候先匹配广播，再匹配多播", 
            "title": "单播、多播、广播"
        }, 
        {
            "location": "/appendix/mac_mask/#_2", 
            "text": "例如 11:1b:cc:dd:ee:ff/11:10:08:00:00:00 表示  地址 11:1b:cc:dd:ee:ff  -  二进制为 00010001:00011011:11001100:11011101:11101110:11111111  掩码 11:10:08:00:00:00  -  二进制为 00010001:00010000:00001000:00000000:00000000:00000000  掩码中为1的，对应到地址的bit不变，掩码中为0的，对应到地址的bit可以为1也可为0，和ip/netmask的算法是类似的，因此这个例子中，可以表示的范围是：  最小： 00010001:00010000:00001000:00000000:00000000:00000000  最大： 11111111:11111111:11111111:11111111:11111111:11111111  转换成16进制，则是：  从 11:10:08:00:00:00 到 ff:ff:ff:ff:ff:ff   Warning  这个例子算出来的最小地址刚好和掩码一样，这只是个巧合", 
            "title": "掩码匹配算法详解"
        }, 
        {
            "location": "/contact/", 
            "text": "E-mail地址:", 
            "title": "七. 联系方式"
        }
    ]
}